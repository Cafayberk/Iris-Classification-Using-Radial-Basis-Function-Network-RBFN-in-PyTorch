{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "SKqFkrH9FbnZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "r0lglYT1EdRm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dataset"
      ],
      "metadata": {
        "id": "Vz-NvoPoFhIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drive way\n",
        "file_path = '/content/drive/MyDrive/iris/iris.data'\n",
        "\n",
        "# Read CSV (or .data) file\n",
        "df = pd.read_csv(file_path, header=None)\n",
        "\n",
        "# Features (X) and target (y)\n",
        "X = df.iloc[:, :-1].values  # First 4 columns\n",
        "y, _ = pd.factorize(df.iloc[:, -1])  # last column\n",
        "\n",
        "# standardize data\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(X)\n",
        "\n",
        "# train test split into two\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)\n",
        "\n",
        "def to_tensor(data, target):\n",
        "    return torch.tensor(data, dtype=torch.float32), torch.tensor(target, dtype=torch.long)\n",
        "\n",
        "X_train, y_train = to_tensor(X_train, y_train)\n",
        "X_test, y_test = to_tensor(X_test, y_test)"
      ],
      "metadata": {
        "id": "0rcggQgVGbAs"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the RBFN model and rbf_kernel"
      ],
      "metadata": {
        "id": "NfC3xwQAFosc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rbf_kernel(X, centers, beta):\n",
        "    return torch.exp(-beta * torch.cdist(X, centers) ** 2)\n",
        "\n",
        "\n",
        "class RBFN(nn.Module):\n",
        "    def __init__(self, input_dim, num_centers, output_dim):\n",
        "        super(RBFN, self).__init__()\n",
        "        nn.Parameter(torch.randn(num_centers, input_dim))\n",
        "        self.centers = nn.Parameter(torch.randn(num_centers, input_dim)) # randomly initialize rbf centers\n",
        "        self.beta = nn.Parameter(torch.ones(1) * 2.0) # The beta parameter will control the width of the RBF.\n",
        "        self.linear = nn.Linear(num_centers, output_dim) # direct output to fully connected layer\n",
        "\n",
        "\n",
        "    def forward(self, x): # forward propagation\n",
        "        # Calculate the rbf kernel function\n",
        "        phi = rbf_kernel(x, self.centers, self.beta)\n",
        "        return self.linear(phi)\n",
        "\n",
        "# model = RBFN(4, 10, 3)"
      ],
      "metadata": {
        "id": "lOUHq-drKtoa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training"
      ],
      "metadata": {
        "id": "zqMy1WTyFwhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_centers = 10\n",
        "model = RBFN(input_dim=4, num_centers=num_centers, output_dim=3)\n",
        "\n",
        "# loss function definition and optimization\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# let's train the model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad() # gradients to zero\n",
        "    outputs = model(X_train) # forward propagation\n",
        "    loss = criterion(outputs, y_train) # calculate loss\n",
        "    loss.backward()\n",
        "    optimizer.step() # update weights\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F__Sr5u-MePP",
        "outputId": "b9eaf685-4136-4ef5-ce84-2227af65ce65"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1.0689\n",
            "Epoch [20/100], Loss: 1.0206\n",
            "Epoch [30/100], Loss: 0.9590\n",
            "Epoch [40/100], Loss: 0.8765\n",
            "Epoch [50/100], Loss: 0.7757\n",
            "Epoch [60/100], Loss: 0.6562\n",
            "Epoch [70/100], Loss: 0.5269\n",
            "Epoch [80/100], Loss: 0.4064\n",
            "Epoch [90/100], Loss: 0.3132\n",
            "Epoch [100/100], Loss: 0.2490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test and evaluation"
      ],
      "metadata": {
        "id": "VATUCfxuFzip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    y_pred = model(X_test) # predict with test data\n",
        "    accuracy = (torch.argmax(y_pred, axis=1) == y_test).float().mean().item() #Â calculate accuracy\n",
        "    print(f'Accuracy: {accuracy * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHyrChpWPJ72",
        "outputId": "1fbfde18-b0c7-407b-b5ba-10ccbe531f34"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.78\n"
          ]
        }
      ]
    }
  ]
}